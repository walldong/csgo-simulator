const fs = require('fs');
const path = require('path');
const https = require('https');
const http = require('http');
const config = require('./config');

// é…ç½®
const CONFIG = {
  CONCURRENT_DOWNLOADS: config.download.concurrent,
  RETRY_ATTEMPTS: config.download.retryAttempts,
  RETRY_DELAY: config.download.retryDelay,
  TIMEOUT: config.download.timeout,
};

// ç›®å½•é…ç½®
const DIRS = {
  IMAGES: path.join(__dirname, '..', config.directories.images),
  CRATES: path.join(__dirname, '..', config.directories.crates),
  SKINS: path.join(__dirname, '..', config.directories.skins),
  COLLECTIONS: path.join(__dirname, '..', config.directories.collections),
};

// ç»Ÿè®¡ä¿¡æ¯
const stats = {
  total: 0,
  downloaded: 0,
  skipped: 0,
  failed: 0,
  startTime: Date.now(),
};

// ç¡®ä¿ç›®å½•å­˜åœ¨
function ensureDir(dir) {
  if (!fs.existsSync(dir)) {
    fs.mkdirSync(dir, { recursive: true });
  }
}

// ä¸‹è½½å›¾ç‰‡å‡½æ•°ï¼ˆå¸¦é‡è¯•ï¼‰
async function downloadImage(url, filepath, retryCount = 0) {
  return new Promise((resolve, reject) => {
    const protocol = url.startsWith('https:') ? https : http;
    
    const request = protocol.get(url, {
      timeout: CONFIG.TIMEOUT,
      headers: {
        'User-Agent': config.network.userAgent,
        ...config.network.headers
      }
    }, (response) => {
      if (response.statusCode !== 200) {
        const error = new Error(`HTTP ${response.statusCode}: ${url}`);
        if (retryCount < CONFIG.RETRY_ATTEMPTS) {
          if (config.logging.showDetails) {
            console.log(`âš ï¸  Retrying (${retryCount + 1}/${CONFIG.RETRY_ATTEMPTS}): ${path.basename(filepath)}`);
          }
          setTimeout(() => {
            downloadImage(url, filepath, retryCount + 1)
              .then(resolve)
              .catch(reject);
          }, CONFIG.RETRY_DELAY);
          return;
        }
        reject(error);
        return;
      }

      const fileStream = fs.createWriteStream(filepath);
      response.pipe(fileStream);

      fileStream.on('finish', () => {
        fileStream.close();
        stats.downloaded++;
        if (config.logging.showProgress) {
          updateProgress();
        }
        resolve();
      });

      fileStream.on('error', (err) => {
        fs.unlink(filepath, () => {}); // åˆ é™¤ä¸å®Œæ•´çš„æ–‡ä»¶
        if (retryCount < CONFIG.RETRY_ATTEMPTS) {
          if (config.logging.showDetails) {
            console.log(`âš ï¸  Retrying (${retryCount + 1}/${CONFIG.RETRY_ATTEMPTS}): ${path.basename(filepath)}`);
          }
          setTimeout(() => {
            downloadImage(url, filepath, retryCount + 1)
              .then(resolve)
              .catch(reject);
          }, CONFIG.RETRY_DELAY);
        } else {
          reject(err);
        }
      });
    });

    request.on('error', (err) => {
      if (retryCount < CONFIG.RETRY_ATTEMPTS) {
        if (config.logging.showDetails) {
          console.log(`âš ï¸  Retrying (${retryCount + 1}/${CONFIG.RETRY_ATTEMPTS}): ${path.basename(filepath)}`);
        }
        setTimeout(() => {
          downloadImage(url, filepath, retryCount + 1)
            .then(resolve)
            .catch(reject);
        }, CONFIG.RETRY_DELAY);
      } else {
        reject(err);
      }
    });

    request.on('timeout', () => {
      request.destroy();
      if (retryCount < CONFIG.RETRY_ATTEMPTS) {
        if (config.logging.showDetails) {
          console.log(`âš ï¸  Timeout, retrying (${retryCount + 1}/${CONFIG.RETRY_ATTEMPTS}): ${path.basename(filepath)}`);
        }
        setTimeout(() => {
          downloadImage(url, filepath, retryCount + 1)
            .then(resolve)
            .catch(reject);
        }, CONFIG.RETRY_DELAY);
      } else {
        reject(new Error(`Timeout: ${url}`));
      }
    });
  });
}

// ä»URLä¸­æå–æ–‡ä»¶å
function getFilenameFromUrl(url) {
  const urlParts = url.split('/');
  return urlParts[urlParts.length - 1];
}

// æ›´æ–°è¿›åº¦æ˜¾ç¤º
function updateProgress() {
  const progress = ((stats.downloaded + stats.skipped) / stats.total * 100).toFixed(1);
  const elapsed = ((Date.now() - stats.startTime) / 1000).toFixed(1);
  process.stdout.write(`\rğŸ“Š Progress: ${progress}% (${stats.downloaded + stats.skipped}/${stats.total}) | â±ï¸  ${elapsed}s | âœ… ${stats.downloaded} | â­ï¸  ${stats.skipped} | âŒ ${stats.failed}`);
}

// å¹¶å‘ä¸‹è½½é˜Ÿåˆ—
class DownloadQueue {
  constructor(concurrency) {
    this.concurrency = concurrency;
    this.running = 0;
    this.queue = [];
  }

  async add(task) {
    return new Promise((resolve, reject) => {
      this.queue.push({ task, resolve, reject });
      this.process();
    });
  }

  async process() {
    if (this.running >= this.concurrency || this.queue.length === 0) {
      return;
    }

    this.running++;
    const { task, resolve, reject } = this.queue.shift();

    try {
      const result = await task();
      resolve(result);
    } catch (error) {
      reject(error);
    } finally {
      this.running--;
      this.process();
    }
  }
}

// å¤„ç†JSONæ–‡ä»¶ä¸­çš„å›¾ç‰‡
async function processJsonFile(jsonPath, outputDir, type) {
  console.log(`\nğŸ“ Processing ${type} from: ${path.basename(jsonPath)}`);
  
  const data = JSON.parse(fs.readFileSync(jsonPath, 'utf8'));
  const imageUrls = new Set();
  
  // é€’å½’æŸ¥æ‰¾æ‰€æœ‰imageå­—æ®µ
  function extractImageUrls(obj) {
    if (typeof obj === 'object' && obj !== null) {
      for (const [key, value] of Object.entries(obj)) {
        if (key === 'image' && typeof value === 'string' && value.startsWith('http')) {
          imageUrls.add(value);
        } else if (typeof value === 'object') {
          extractImageUrls(value);
        }
      }
    } else if (Array.isArray(obj)) {
      obj.forEach(item => extractImageUrls(item));
    }
  }
  
  extractImageUrls(data);
  
  console.log(`Found ${imageUrls.size} unique images in ${type}`);
  
  // åˆ›å»ºä¸‹è½½é˜Ÿåˆ—
  const downloadQueue = new DownloadQueue(CONFIG.CONCURRENT_DOWNLOADS);
  const downloadPromises = [];
  
  // å‡†å¤‡ä¸‹è½½ä»»åŠ¡
  for (const url of imageUrls) {
    const filename = getFilenameFromUrl(url);
    const filepath = path.join(outputDir, filename);
    
    // å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
    if (fs.existsSync(filepath)) {
      stats.skipped++;
      if (config.logging.showProgress) {
        updateProgress();
      }
      continue;
    }
    
    const downloadTask = async () => {
      try {
        await downloadImage(url, filepath);
        if (config.logging.showDetails) {
          console.log(`\nâœ… Downloaded: ${filename}`);
        }
      } catch (error) {
        stats.failed++;
        if (config.logging.showProgress) {
          updateProgress();
        }
        if (config.logging.showDetails) {
          console.error(`\nâŒ Failed to download ${filename}:`, error.message);
        }
        throw error;
      }
    };
    
    downloadPromises.push(downloadQueue.add(downloadTask));
  }
  
  // ç­‰å¾…æ‰€æœ‰ä¸‹è½½å®Œæˆ
  await Promise.allSettled(downloadPromises);
  console.log(`\nâœ… Completed processing ${type}`);
}

// æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
function showFinalStats() {
  const totalTime = ((Date.now() - stats.startTime) / 1000).toFixed(1);
  console.log('\n' + '='.repeat(60));
  console.log('ğŸ“Š DOWNLOAD STATISTICS');
  console.log('='.repeat(60));
  console.log(`Total images found: ${stats.total}`);
  console.log(`Successfully downloaded: ${stats.downloaded}`);
  console.log(`Skipped (already exists): ${stats.skipped}`);
  console.log(`Failed: ${stats.failed}`);
  console.log(`Total time: ${totalTime} seconds`);
  console.log(`Average speed: ${(stats.downloaded / totalTime).toFixed(2)} images/second`);
  console.log(`Images saved to: ${DIRS.IMAGES}`);
  console.log('='.repeat(60));
}

// ä¸»å‡½æ•°
async function main() {
  console.log('ğŸš€ Starting advanced image download process...');
  console.log(`âš™ï¸  Configuration: ${CONFIG.CONCURRENT_DOWNLOADS} concurrent downloads, ${CONFIG.RETRY_ATTEMPTS} retry attempts`);
  
  // åˆ›å»ºç›®å½•
  Object.values(DIRS).forEach(ensureDir);
  
  const publicDir = path.join(__dirname, '..', 'public');
  
  try {
    // é¦–å…ˆç»Ÿè®¡æ€»å›¾ç‰‡æ•°é‡
    const files = ['crates.json', 'skins.json', 'collections.json'];
    for (const file of files) {
      const data = JSON.parse(fs.readFileSync(path.join(publicDir, file), 'utf8'));
      const imageUrls = new Set();
      
      function countImages(obj) {
        if (typeof obj === 'object' && obj !== null) {
          for (const [key, value] of Object.entries(obj)) {
            if (key === 'image' && typeof value === 'string' && value.startsWith('http')) {
              imageUrls.add(value);
            } else if (typeof value === 'object') {
              countImages(value);
            }
          }
        } else if (Array.isArray(obj)) {
          obj.forEach(item => countImages(item));
        }
      }
      
      countImages(data);
      stats.total += imageUrls.size;
    }
    
    console.log(`ğŸ“Š Total unique images to process: ${stats.total}`);
    
    // å¤„ç†å„ä¸ªJSONæ–‡ä»¶
    await processJsonFile(
      path.join(publicDir, 'crates.json'),
      DIRS.CRATES,
      'crates'
    );
    
    await processJsonFile(
      path.join(publicDir, 'skins.json'),
      DIRS.SKINS,
      'skins'
    );
    
    await processJsonFile(
      path.join(publicDir, 'collections.json'),
      DIRS.COLLECTIONS,
      'collections'
    );
    
    showFinalStats();
    
  } catch (error) {
    console.error('\nâŒ Error during download process:', error);
    process.exit(1);
  }
}

// è¿è¡Œè„šæœ¬
if (require.main === module) {
  main();
}

module.exports = { downloadImage, processJsonFile, DownloadQueue };